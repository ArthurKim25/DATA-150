### Arthur Kim
### Professor Brewer
### 16 Nov 2021

Around the start of the 21st century, the concept of an autonomous vehicle was beginning to become a reality. Although initial tests in 2004 performed poorly, it jumpstarted endeavors to design self-driving cars.  Despite the newness of this technology as well as machine learning and articifial intelligence in general, the show promising results for the future. Like with real driving however, self-driving cars must be able to make proper judgements given any situation, such as when to stop for pedestrians versus random objects. When discussing the impact of self-driving cars on society, it is important to consider all sides of the issue. Although many people will benefit from the proliferation of autonomous vehicles, there are several ethical issues that can arise. Therefore, if autonomous vehicles are to be truly beneficial for society, they need to address these issues.

Evidently, the developmental process of machine learning with autonomous vehicles has been applied across a wide variety of disciplines. In fact, many experts agree that machine learning to some extent will find its way into every discipline because of its ability to make predictions and analyze data to a level not feasible by humans alone.  Therefore, machine learning has an overall positive impact on humanity. However, Max Tegmark, a leading pioneer in AI safety says that in order to prevent an existential disaster, it is necessary to concretely understand how AI works. Although machine learning promises many benefits, it would be in our best interest to better understand how they work. Without a doubt, autonomous vehicles show great promise for the well-being of humanity. The article discusses how self-driving cars will vastly improve the global economy and save 600000 lives, which will result in greater livelihoods across the globe. However, one of the main issues brought up by the article is the fact that autonomous vehicles are going to have to make decisions about predictive judgement, including whether to follow the law or save a life. Tegmark says that it is ethically impossible to leave the decision to take or spare a life to an AI, so by making vehicles fully autonomous, we would be breaching a major moral principle. To make matters worse, if self-driving cars become mainstream, that may make other entities in power more likely to be willing to violate important morals, which would have disasterous consequences for society.  Therefore, in order to prevent society from devolving into immorality, I think it is essential that some aspects of autonomous vehicles be left to the control of humans regardless of how advanced they can get. That way, situations of life or death can be handled by human beings, which according to Tegmark is an essential ethical standard. Machine learning and self-driving cars an b great for humanity, but only if the ethical shortcomings are properly addressed.
